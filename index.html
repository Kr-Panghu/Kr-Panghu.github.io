<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="google-site-verification" content="2y369S65gf5QXIGZ45g2bzuGBrMQxswQK7LVTa82V6I" />
  <title>Kangrui Cen</title>

  <meta name="author" content="Kangrui Cen">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">
</head>


<body>
  <header>
    <div class="logo">
      <a href="https://Kr-Panghu.github.io">My Website</a>
    </div>
    <nav class="nav">
      <ul>
        <li><a href="https://Kr-Panghu.github.io">Home</a></li>
        <li><a href="mailto:kr2256671169@sjtu.edu.cn">Contact</a></li>
      </ul>
    </nav>
  </header>
  
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:75px;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <!-- Bio -->
          <table class="profile-table">
            <tbody>
              <tr>
                <td class="profile-description">
                  <p class="profile-name">Kangrui Cen</p>
                  <p class="profile-bio">Hi! I am currently a research intern at OPPO Research Institute, supervised by <strong><a href="https://www4.comp.polyu.edu.hk/~cslzhang/">Prof. Lei Zhang</a></strong>.
                    Before that, I recieved my Bachelor degree in Computer Science from <strong><a href="https://en.sjtu.edu.cn/">Shanghai Jiao Tong University</a></strong>, where I am a member of <strong><a href="https://jhc.sjtu.edu.cn">John Hopcroft Honors Class</a></strong>.</p>
                  <p class="profile-bio">Previously, I'm honored to collaborate with <strong><a href="https://faculty.ucmerced.edu/mhyang/">Prof. Ming-Hsuan Yang</a></strong> at <strong> UCM</strong>, <strong><a href="https://ckkelvinchan.github.io/">Dr. Kelvin C.K. Chan</a></strong> at  <strong> Google DeepMind</strong>, and <strong><a href="https://jhc.sjtu.edu.cn/~xiaohongliu/">Prof. Xiaohong Liu</a></strong> at <strong> SJTU</strong>.</p>
                  <!-- <p class="profile-apply">I'm now busy preparing my PhD/MS applications for Fall 2025, wish all the best!</p> -->
                  <p class="profile-links">
                    <a href="mailto:kr2256671169@sjtu.edu.cn">Email</a> /
                    <a href="files/CV-Kangrui_Cen.pdf">CV</a> /
                    <a href="https://scholar.google.com/citations?hl=en&user=iwDymkMAAAAJ">Google Scholar</a> /
                    <a href="https://github.com/Kr-Panghu">Github</a> /
                    <a href="https://instagram.com/krpanghu">Instagram</a>
                  </p>
                </td>
                <!-- profile image -->
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="files/kangrui.JPG"><img style="width:80%;max-width:80%" alt="profile photo"
                      src="files/kangrui.JPG" class="prof-image"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <!--News-->
          <!-- <table class="section-table">
            <tbody>
              <tr>
                <td class="section-heading">
                  News
                </td>
              </tr>
            </tbody>

          </table>
          <table class="content-table">
            <tbody>
                <tr>
                    <td style="padding:10px 10px;width:100%;vertical-align:middle;text-align:justify">
                        <p style="margin-left: 5%; text-align:left">
                            <strong>[2024.08]</strong> I became a reviewer for ICLR 25!
                            <br>
                            <strong>[2024.06]</strong> &#x1F389; I got the SenseTime Scholarship!
                            <br>
                            <strong>[2024.05]</strong> I became a reviewer for NeurIPS 24!
                            <br>
                            <strong>[2024.05]</strong> &#x1F389; I got the `TOP 100 Students in Sichuan University'!
                            <br>
                            <strong>[2024.04]</strong> I became a reviewer for Information Fusion!
                            <br>
                            <strong>[2024.03]</strong> I became a reviewer for ECCV 24!
                            <br>
                            <strong>[2024.01]</strong> I became a reviewer for ACM MM 24!
                            <br>  
                            <strong>[2023.08]</strong> I became a reviewer for IJCV!
                            <br>  
                            <strong>[2023.07]</strong> &#x1F389; Our work <a href="https://arxiv.org/pdf/2308.06776.pdf"> SCPGabNet </a> is accepted to ICCV 2023! &#x1F389.
                        </p>
                    </td>
                </tr>
            </tbody>
        </table> -->

          

          <!-- Research Interests -->
          <table
          class="section-table">
            <tbody>
              <tr>
                <td class="section-heading">
                  Research Interests
                </td>
              </tr>
            </tbody>
          </table>
          <table
          class="content-table">
            <tbody>
              <tr>
                <td style="padding:0px 10px;width:100%;vertical-align:middle;text-align:justify">
                  <p style="text-align:justify">
                    I am broadly interested in Computer Vision, including Image/Video Editing/Enhancement/Generation, 3D Generation/Reconstruction and so on.
                  </p>
                </td>
              </tr>

            </tbody>
          </table>



          <!-- Publications -->
          <table
          class="section-table">
            <tbody>
              <tr>
                <td class="section-heading">
                  Papers
                </td>
              </tr>
            </tbody>
          </table>
          <table
          class="content-table">
            <tbody>

              <tr>
                <td style="padding:10px 20px;width:45%;vertical-align:middle">
                  <img src="figs/publications/LayerT2V-teasor.jpg" class="pub-image" height="180">
                </td>
                <td width="60%" valign="middle">
                  <!-- <papertitle><em style="color: rgb(255, 30, 30);">[NEW]</em>  -->
                  LayerT2V: Interactive Multi-Object Trajectory Layering for Video Generation
                  <!-- </papertitle> -->
                  <br>
                  <u>Kangrui Cen</u>,
                  Baixuan Zhao,
                  Yi Xin,
                  Siqi Luo,
                  Guangtao Zhai,
                  Xiaohong Liu
                  <br>
                  <em style="color: rgb(127, 29, 7);">arXiv PrePrint</em>
                  <br>
                  <details>
                    <summary><strong>Abstract:</strong></summary>
                    <p><small_font_text>Controlling object motion trajectories in Text-to-Video (T2V) generation is a challenging and 
                      relatively under-explored area, particularly in scenarios involving multiple moving objects. Most community models 
                      and datasets in the T2V domain are designed for single-object motion, limiting the performance of current generative 
                      models in multi-object tasks. Additionally, existing motion control methods in T2V either lack support for multi-object 
                      motion scenes or experience severe performance degradation when object trajectories intersect, primarily due to the 
                      semantic conflicts in colliding regions. To address these limitations, we introduce LayerT2V, the first approach 
                      for generating video by compositing background and foreground objects layer by layer. This layered generation enables
                       flexible integration of multiple independent elements within a video, positioning each element on a distinct “layer” 
                       and thus facilitating coherent multi-object synthesis while enhancing control over the generation process. Extensive
                        experiments demonstrate the superiority of LayerT2V in generating complex multi-object scenarios, showcasing 1.4&times; 
                        and 4.5&times; improvements in mIoU and AP50 metrics over state-of-the-art (SOTA) methods. The code will be made 
                        publicly available. Project Page: <a href="https://kr-panghu.github.io/LayerT2V/"><small_font_text>https://kr-panghu.github.io/LayerT2V/</small_font_text></a></small_font_text></p>
                  </details>
                  <a href="https://kr-panghu.github.io/LayerT2V/">Project Page</a>
                  / <a href="https://github.com/Kr-Panghu/LayerT2V-public">Code</a>
                  / <a href="https://arxiv.org/abs/2508.04228">arXiv PrePrint</a>
                </td>
              </tr>

              <tr>
                <td style="padding:10px 20px;width:45%;vertical-align:middle">
                  <img src="figs/publications/Awesome-Parameter-Efficient-Transfer-Learning.png" class="pub-image" height="180">
                </td>
                <td width="60%" valign="middle">
                  <!-- <papertitle><em style="color: rgb(255, 30, 30);">[NEW]</em>  -->
                  Parameter-Efficient Fine-Tuning for Pre-Trained Vision Models: A Survey and Benchmark
                  <!-- </papertitle> -->
                  <br>
                  Yi Xin, Jianjiang Yang, Siqi Luo, Yuntao Du, Qi Qin, <u>Kangrui Cen</u>, Yangfan He, Bin Fu, Xiaokang Yang, Guangtao Zhai, Ming-Hsuan Yang, Xiaohong Liu
                  <br>
                  <em style="color: rgb(127, 29, 7);">Under Review</em>
                  <br>
                  <details>
                    <summary><strong>Abstract:</strong></summary>
                    <p><small_font_text>Pre-trained vision models (PVMs) have demonstrated remarkable adaptability across a wide range of downstream vision tasks,
                       showcasing exceptional performance. However, as these models scale to billions or even trillions of parameters, conventional full fine-tuning
                        has become increasingly impractical due to its high computational and storage demands. To address these challenges, parameter-efficient
                         fine-tuning (PEFT) has emerged as a promising alternative, aiming to achieve performance comparable to full fine-tuning while making minimal 
                         adjustments to the model parameters. This paper presents a comprehensive survey of the latest advancements in the visual PEFT field, systematically 
                         reviewing current methodologies and categorizing them into four primary categories: addition-based, partial-based, unified-based, and multi-task
                          tuning. In addition, this paper offers an in-depth analysis of widely used visual datasets and real-world applications where PEFT methods have 
                          been successfully applied. Furthermore, this paper introduces the V-PEFT Bench, a unified benchmark designed to standardize the evaluation 
                          of PEFT methods across a diverse set of vision tasks, ensuring consistency and fairness in comparison. Finally, the paper outlines potential 
                          directions for future research to propel advances in the PEFT field. A comprehensive collection of resources is available 
                          <a href="https://github.com/synbol/Awesome-Parameter-Efficient-Transfer-Learning"><small_font_text>at this https URL</small_font_text></a></small_font_text></p>
                  </details>
                  <a href="https://github.com/synbol/Awesome-Parameter-Efficient-Transfer-Learning">Collection of Resources</a>
                  / <a href="https://arxiv.org/abs/2402.02242">arXiv PrePrint</a>
                </td>
              </tr>

            </tbody>
          </table>
               
          <table class="section-table">
            <tbody>
              <tr>
                <td class="section-heading">
                  Experience
                </td>
              </tr>
            </tbody>
          </table>

          <table class="content-table">
            <tbody>

              <tr>
                <td class="section-image-large">
                  <img src="figs/oppo-logo.png" alt="Oppo logo" class="section-image-large">
                </td>

                <td class="section-content">
                  <div class="section-title">
                    Oppo Research Institute
                  </div>
                  <div class="section-details">
                    <span class="section-date">2025.07 ~ Present </span>
                    <br>
                    Shenzhen, Guangdong, China
                    <br>
                    Research Intern
                    <br>
                    Supervisor: <a href="https://www4.comp.polyu.edu.hk/~cslzhang/">Prof. Lei Zhang</a>
                  </div>
                </td>
              </tr>

              <tr>
                <td class="section-image-large">
                  <img src="figs/Google_logo.png" alt="Google logo" class="section-image-large">
                </td>

                <td class="section-content">
                  <div class="section-title">
                    Google DeepMind
                  </div>
                  <div class="section-details">
                    <span class="section-date">2024.06 ~ Present </span>
                    <br>
                    Seattle, WA, USA
                    <br>
                    Remote Collaborator
                    <br>
                    Supervisor: <a href="https://ckkelvinchan.github.io/">Dr. Kelvin C.K. Chan</a>; <a href="https://faculty.ucmerced.edu/mhyang/">Prof. Ming-Hsuan Yang</a>
                  </div>
                </td>
              </tr>

              <tr>
                <td class="section-image-large">
                  <img src="figs/UCM_Seal_FullColor.jpeg" alt="UCM logo" class="section-image-large">
                </td>

                <td class="section-content">
                  <div class="section-title">
                    University of California, Merced
                  </div>
                  <div class="section-details">
                    <span class="section-date">2024.04 ~ Present </span>
                    <br>
                    Merced, CA, USA
                    <br>
                    Exchange Scholar
                    <br>
                    Supervisor: <a href="https://faculty.ucmerced.edu/mhyang/">Prof. Ming-Hsuan Yang</a>
                  </div>
                </td>
              </tr>

              <tr>
                <td class="section-image-large">
                  <img src="figs/SJTU_logo.png" alt="SJTU_logo" class="section-image-large">
                </td>

                <td class="section-content">
                  <div class="section-title">
                    Shanghai Jiao Tong University
                  </div>
                  <div class="section-details">
                    <span class="section-date">2021.09 ~ 2025.06</span>
                    <br>
                    Shanghai, China
                    <br>
                    <!-- GPA: 87.48/100 -->
                    <!-- <br> -->
                    B.S. in Computer Science (Zhiyuan Honors Program, John Hopcroft Class).
                  </div>
                </td>
              </tr>         

            </tbody>
          </table>

          <!-- Course Projects -->
          <table
          class="section-table">
            <tbody>
              <tr>
                <td class="section-heading">
                  Course Projects
                </td>
              </tr>
            </tbody>
          </table>
          <table
          class="content-table">
            <tbody>

               <tr>
                <td style="padding:10px 20px;width:40%;vertical-align:middle">
                  <img src="figs/CourseProjects/CS3964_image.png" class="pub-image" height="180">
                </td>
                <td width="60%" valign="middle">
                  <papertitle>Bootstrapping Diffusion Models: Iterative Synthetic Data Generation for Self-Supervised Learning</papertitle>
                  <br>
                  Kangrui Cen,
                  Yuxiao Yang,
                  Shuze Chen,
                  Ziqi Huang,
                  Tianyu Zhang
                  <br>
                  <em>CS3964: Image Processing and Computer Vision</em>, 2023 Fall
                  <br> 
                  <details>
                    <summary><strong>Summary:</strong></summary>
                    <p><small_font_text>We introduce a novel bootstrapping approach for training generative models. Specifically, we construct synthetic datasets by combining generated samples from previous iterations with real data. By recycling samples over successive generations, this technique reduces the dependence on large curated datasets while producing varied outputs.</small_font_text></p>
                  </details>
                  <p>Advisor: <a href="http://www.qingyuan.sjtu.edu.cn/a/Jianfu-Zhang.html">Prof. Jianfu Zhang</a>, &nbsp &nbsp <a href="https://github.com/Kr-Panghu/Bootstrapping_Diffusion">Code</a>
                    / <a href="https://Kr-Panghu.github.io/files/CourseProjects/CS3964.pdf">Project Paper</a></p>
                </td>
              </tr>

              <tr>
                <td style="padding:10px 20px;width:40%;vertical-align:middle">
                  <img src="figs/CourseProjects/Information_theory_image.png" class="pub-image" height="180">
                </td>
                <td width="60%" valign="middle">
                  <papertitle>Using information theoretic metrics to study the importance of individual neurons in DNNs</papertitle>
                  <br>
                  Kangrui Cen
                  <br>
                  <em>ICE2601: Information Theory</em>, 2023 Spring
                  <br> 
                  <details>
                    <summary><strong>Summary:</strong></summary>
                    <p><small_font_text>Using information theoretic metrics for node pruning to learn the importance of individual neurons at different levels in the whole DNN. Entropy, Mutual information and KL-Selectivity are used to determine the order of ablation.</small_font_text></p>
                  </details>
                  <p>Advisor: <a href="https://www.cs.sjtu.edu.cn/~chengfan/">Prof. Fan Cheng</a>, &nbsp &nbsp <a href="https://github.com/Kr-Panghu/UNN-on-MNIST">Code</a>
                    / <a href="https://Kr-Panghu.github.io/files/CourseProjects/Information_theory_paper.pdf">Project Paper</a> / <a href="https://Kr-Panghu.github.io/files/CourseProjects/Information_theory_slides.pdf">Slides</a></p> 
                </td>
              </tr>

              <tr>
                <td style="padding:10px 20px;width:40%;vertical-align:middle">
                  <img src="figs/CourseProjects/CS2107_image.png" class="pub-image" height="180">
                </td>
                <td width="60%" valign="middle">
                  <papertitle>GAMES101 RUST (Designed when I was a TA for <em>Programming and Data Structure III</em>)</papertitle>
                  <!-- <br>
                  Kangrui Cen -->
                  <br>
                  <em>CS2107: Programming and Data Structure III</em>, 2023 Summer
                  <br> 
                  <details>
                    <summary><strong>Summary:</strong></summary>
                    <p><small_font_text>This is the course project I designed on my own for CS2107 where I served as TA, which is basically generated from Graphics And Mixed Environemnt Seminar, Lingqi Yan, UCSB, but chooses to use a more modern programming language, i.e. Rust. The project includes 3 LABs, simply allows students to learn the basics of rasterization in graphics and, most importantly, to have fun.</small_font_text></p>
                  </details>
                  <p>Advisor: Prof. Qinsheng Ren,  &nbsp &nbsp <a href="https://github.com/Kr-Panghu/GAMES101-RUST-2023">Public Template</a>
                    / <a href="https://Kr-Panghu.github.io/files/CourseProjects/CS2107.pdf">Project Tutorial</a></p> 
                </td>
              </tr>

              <tr>
                <td style="padding:10px 20px;width:40%;vertical-align:middle">
                  <img src="figs/CourseProjects/llm_framework.jpg" class="pub-image" height="180">
                </td>
                <td width="60%" valign="middle">
                  <papertitle>Stop Running Your Mouth: Machine Unlearning 4 Pre-Trained LLMs</papertitle>
                  <br>
                  Kangrui Cen, Tianyu Zhang
                  <br>
                  <em>CS3966: Natural Language Processing and Large Language Model</em>, 2024 Spring
                  <br> 
                  <details>
                    <summary><strong>Summary:</strong></summary>
                    <p><small_font_text>We employ the Machine Unlearning approach to mitigate the retention of unethical data within LLMs and prevent the generation of harmful responses. We carefully design a method to ensure: (1) For a negative Q&A training pair, the LLM forgets its original response to the input; (2) The LLM randomly maps negative prompts to any output distribution within its output space; (3) The LLM maintains a level of general language ability close to its original state post-unlearning.</small_font_text></p>
                  </details>
                  <p>Advisor: <a href="https://wangruinlp.github.io/">Prof. Rui Wang</a>,
                    <br> 
                    <a href="https://github.com/Kr-Panghu/LLM_Unlearning">Code</a>
                    / <a href="https://Kr-Panghu.github.io/files/CourseProjects/LLM_Project_2024.pdf#page=3">Project Paper</a>
                    / <a href="https://Kr-Panghu.github.io/files/CourseProjects/LLM_Project_2024.pdf#page=1">Simulative Rebuttal</a> 
                    / <a href="https://Kr-Panghu.github.io/files/CourseProjects/NLP_Final_6-3.pdf">Slides</a> </p> 
                </td>
              </tr>
              

            </tbody>
          </table>
          
          
          <!-- Honors -->
          <table
          class="section-table">
            <tbody>
              <tr>
                <td class="section-heading">
                  Honors
                </td>
              </tr>
            </tbody>
          </table>
          <table
          class="content-table">
            <tbody>

              <tr>
                <td style="padding:5px 50px;width:100%;vertical-align:middle">
                  <honor>Outstanding Graduates of Shanghai Jiao Tong University</honor>, 2025
                </td>
              </tr>

              <tr>
                <td style="padding:5px 50px;width:100%;vertical-align:middle">
                  <honor>Merit Scholarship, B Level</honor> (top 10%), SJTU, 2022, 2023
                </td>
              </tr>

              <tr>
                <td style="padding:5px 50px;width:100%;vertical-align:middle">
                  <honor>Meritorious Winner of MCM/ICM</honor> (top 7%), 2022
                </td>
              </tr>

              <tr>
                <td style="padding:5px 50px;width:100%;vertical-align:middle">
                  <honor>Zhiyuan Honors Scholarship</honor> (top 5%), SJTU, 2021, 2022, 2023
                </td>
              </tr>
                    
            </tbody>
          </table>

          <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=znsqfXtHntuY52UPpWHmPcPtQkIbNXTTxn4xGiMyUH4&cl=ffffff&w=a"></script>           
          
        </td>
      </tr>
  </table>
  <script>
  // Get the header
  var header = document.querySelector("header");

  // When the user scrolls down 20px from the top of the document, hide the header
  window.onscroll = function() {
    if (window.pageYOffset > 20) {
      header.style.transform = "translateY(-100%)";
    } else {
      header.style.transform = "translateY(0)";
    }
  }

  </script>

<!-- Cloudflare Web Analytics -->
<script defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon='{"token": "c3f89b2d86fd4bdb84e54ee4be31ca44"}'></script>
<!-- End Cloudflare Web Analytics -->

</body>

</html>

