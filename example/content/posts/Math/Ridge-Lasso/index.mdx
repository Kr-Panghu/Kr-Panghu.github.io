---
title: "The influence on $\beta$ when combining Rigde and Lasso Regularization"
tags: ["ML"]
date: 2024-06-11
cover: "./preview.png"
path: "posts/Math/Ridge-Lasso"
---

In Machine learning, Ridge and Lasso are two common regularization methods.

The equation of Ridge and Lasso are as follows:

Ridge: $L_{ridge} = \sum_{i=1}^{n} (y_i - \beta_0 - \sum_{j=1}^{p} \beta_j x_{ij})^2 + \lambda \sum_{j=1}^{p} \beta_j^2$

Lasso: $L_{lasso} = \sum_{i=1}^{n} (y_i - \beta_0 - \sum_{j=1}^{p} \beta_j x_{ij})^2 + \lambda \sum_{j=1}^{p} |\beta_j|$

We know that Ridge will penalize those dimensions with large $\beta$, which results in a dense solution. Lasso will penalize those dimensions with small $\beta$, which results in a sparse solution.

However, what if we combine Ridge and Lasso together? That is, we use the following equation:

$$
\mathcal{L}=\|Y-X \beta\|_2^2+\lambda_1\|\beta\|^2+\lambda_2\|\beta\|_1
$$

Then what will happen to the $\beta$? Will it be sparse or dense?
